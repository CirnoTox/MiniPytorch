{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 函数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./python\")\n",
    "from tic_toc_timer import tic, toc\n",
    "import numpy as np\n",
    "import mpt\n",
    "import mpt.nn as nn\n",
    "\n",
    "# Wrtie acc to csv file\n",
    "def writeAccToFile(train_acc, time, model_name):\n",
    "    with open(\"./result/\"+model_name+\".csv\", \"w\") as f:\n",
    "        f.write(\"n*100batches, train_acc, time\\n\")\n",
    "        for i in range(len(train_acc)):\n",
    "            # using %\n",
    "            f.write(\"{:}, {:.2f}%, {:} seconds\\n\".format(\n",
    "                i+1,train_acc[i]*100, time[i]))\n",
    "    print(\"Write to file successfully\")\n",
    "\n",
    "\n",
    "# Load Data\n",
    "def loadData():\n",
    "    data_dir = \"./data/\"\n",
    "    batch_size = 100\n",
    "    train_dataset = mpt.data.MNISTDataset(\n",
    "        data_dir+\"/train-images-idx3-ubyte.gz\",\n",
    "        data_dir+\"/train-labels-idx1-ubyte.gz\"\n",
    "    )\n",
    "    test_dataset = mpt.data.MNISTDataset(\n",
    "        data_dir+\"/t10k-images-idx3-ubyte.gz\",\n",
    "        data_dir+\"/t10k-labels-idx1-ubyte.gz\"\n",
    "    )\n",
    "    train_dataloader = mpt.data.DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "    test_dataloader = mpt.data.DataLoader(\n",
    "        dataset=test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "    return train_dataset, train_dataloader, test_dataset, test_dataloader\n",
    "\n",
    "# return: loss, error\n",
    "def loss_err(h, y):\n",
    "    lossModule = nn.SoftmaxLoss()\n",
    "    return (\n",
    "        lossModule.forward(h, y),\n",
    "        np.sum(h.numpy().argmax(axis=1) != y.numpy(), dtype=np.float32)\n",
    "    )\n",
    "\n",
    "# epoch\n",
    "\n",
    "\n",
    "def epoch(dataloader: mpt.data.DataLoader,\n",
    "          model: mpt.nn.Module,\n",
    "          opt: mpt.optim.Optimizer = None,\n",
    "          # record acc, time\n",
    "          accList=None,timeList=None):\n",
    "    np.random.seed(4)\n",
    "\n",
    "    if opt is None:\n",
    "        model.eval()\n",
    "    else:\n",
    "        model.train()\n",
    "    loss = 0\n",
    "    err = 0\n",
    "    num_sample = 0\n",
    "\n",
    "    tic()\n",
    "    for i, data in enumerate(dataloader):\n",
    "        imgs = data[0]\n",
    "        labels = data[1]\n",
    "        forwardRes = model.forward(imgs)\n",
    "        iLoss, iError = loss_err(forwardRes, labels)\n",
    "        loss += iLoss.numpy()[0]\n",
    "        err += iError\n",
    "        num_sample += labels.shape[0]\n",
    "        if opt is not None:\n",
    "            iLoss.backward()\n",
    "            opt.step()\n",
    "        # every 50 batches, push acc and time to list\n",
    "        if i % 50 == 0:\n",
    "            time=toc().seconds\n",
    "            accList.append(err/num_sample)\n",
    "            timeList.append(time)\n",
    "            tic()\n",
    "\n",
    "    return (err/num_sample, loss/i)\n",
    "\n",
    "\n",
    "# model\n",
    "# Simple NN\n",
    "def simple_nn():\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(784, 20),\n",
    "        nn.Linear(20, 10)\n",
    "    ), \"simple_nn\"\n",
    "\n",
    "# ResNet\n",
    "def ResidualBlock(dim, hidden_dim, norm=nn.BatchNorm1d, drop_prob=0.1):\n",
    "    return nn.Sequential(\n",
    "        nn.Residual(\n",
    "            nn.Sequential(\n",
    "                nn.Linear(dim, hidden_dim),\n",
    "                norm(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(drop_prob),\n",
    "                nn.Linear(hidden_dim, dim),\n",
    "                norm(dim))\n",
    "        ),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "\n",
    "def MLPResNet(dim, hidden_dim=100, num_blocks=3, num_classes=10, norm=nn.BatchNorm1d, drop_prob=0.1):\n",
    "    ls = [nn.Linear(dim, hidden_dim), nn.ReLU()]\n",
    "    for _ in range(num_blocks):\n",
    "        ls.append(\n",
    "            ResidualBlock(hidden_dim, hidden_dim//2,\n",
    "                          norm, drop_prob)\n",
    "        )\n",
    "    ls.append(nn.Linear(hidden_dim, num_classes))  # 分类层\n",
    "    return nn.Sequential(*ls), \"MLPResNet\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_nn SGD\n",
      "TRAIN\n",
      "Err | Loss\n"
     ]
    }
   ],
   "source": [
    "train_acc, train_loss = None, None\n",
    "\n",
    "modelSimpleNN = simple_nn()\n",
    "modelResNet = MLPResNet(784, hidden_dim=100)\n",
    "optSGD = mpt.optim.SGD\n",
    "optAdam = mpt.optim.Adam\n",
    "\n",
    "\n",
    "# train 2*2, and visualize\n",
    "modelList = [modelSimpleNN]\n",
    "# modelList = [modelSimpleNN, modelResNet]\n",
    "optList = [optSGD, optAdam]\n",
    "\n",
    "accList = [1,2,3]\n",
    "timeList = [1,2,3]\n",
    "for (model, opt) in [(model, opt) for model in modelList for opt in optList]:\n",
    "    [train_dataset, train_dataloader, test_dataset, test_dataloader] = loadData()\n",
    "    thisOpt = opt(model[0].parameters(), lr=0.1, weight_decay=0.001)\n",
    "    print(model[1], type(thisOpt).__name__)\n",
    "    print(\"TRAIN\")\n",
    "    print(\"Err | Loss\")\n",
    "    for _ in range(10):\n",
    "        train_acc, train_loss = epoch(\n",
    "            train_dataloader, model=model[0], opt=thisOpt,\n",
    "            accList=accList, timeList=timeList)\n",
    "    print(\"TEST\")\n",
    "    test_acc, test_loss = epoch(test_dataloader, model=model[0], opt=None,\n",
    "                                accList=accList, timeList=timeList)\n",
    "    \n",
    "    writeAccToFile(accList, timeList, model[1]+\"_\"+type(thisOpt).__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'simple_nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[39m# use different learning rate\u001b[39;00m\n",
      "\u001b[1;32m      2\u001b[0m train_acc, train_loss \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;32m----> 4\u001b[0m modelSimpleNN \u001b[39m=\u001b[39m simple_nn()\n",
      "\u001b[1;32m      5\u001b[0m modelResNet \u001b[39m=\u001b[39m MLPResNet(\u001b[39m784\u001b[39m, hidden_dim\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n",
      "\u001b[1;32m      6\u001b[0m optSGD \u001b[39m=\u001b[39m mpt\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'simple_nn' is not defined"
     ]
    }
   ],
   "source": [
    "# use different learning rate\n",
    "train_acc, train_loss = None, None\n",
    "\n",
    "modelSimpleNN = simple_nn()\n",
    "modelResNet = MLPResNet(784, hidden_dim=100)\n",
    "optSGD = mpt.optim.SGD\n",
    "optAdam = mpt.optim.Adam\n",
    "\n",
    "\n",
    "# train 2*2, and visualize\n",
    "modelList = [modelSimpleNN, modelResNet]\n",
    "optList = [optSGD, optAdam]\n",
    "\n",
    "train_accList = []\n",
    "train_lossList = []\n",
    "\n",
    "test_accList = []\n",
    "test_lossList = []\n",
    "timeList = []\n",
    "for (model, opt) in [(model, opt) for model in modelList for opt in optList]:\n",
    "    [train_dataset, train_dataloader, test_dataset, test_dataloader] = loadData()\n",
    "    thisOpt = opt(model[0].parameters(), lr=0.001, weight_decay=0.001)\n",
    "    print(model[1], opt)\n",
    "    print(\"Err | Loss\")\n",
    "    tic()\n",
    "    for _ in range(10):\n",
    "        train_acc, train_loss = epoch(\n",
    "            train_dataloader, model=model[0], opt=thisOpt)\n",
    "    print(\"TEST\")\n",
    "    test_acc, test_loss = epoch(test_dataloader, model=model[0])\n",
    "    t = toc()\n",
    "\n",
    "    timeList.append(t)\n",
    "    train_lossList.append(train_loss)\n",
    "    test_lossList.append(test_loss)\n",
    "    train_accList.append(train_acc)\n",
    "    test_accList.append(test_acc)\n",
    "    print(\"time: \", t, \" seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accList =  [0.15671666666666667, 0.0758, 0.11516666666666667, 0.014366666666666666]\n",
      "train_lossList =  [0.5967742698391278, 0.27257578710714975, 0.3863513117780288, 0.045549460020071514]\n",
      "test_accList =  [0.1456, 0.0763, 0.0895, 0.0297]\n",
      "test_lossList =  [0.5570591828227043, 0.27045953899621966, 0.2983111513406038, 0.09459613444283604]\n",
      "timeList =  [datetime.timedelta(seconds=64, microseconds=939863), datetime.timedelta(seconds=118, microseconds=871126), datetime.timedelta(seconds=711, microseconds=642097), datetime.timedelta(seconds=840, microseconds=721068)]\n"
     ]
    }
   ],
   "source": [
    "print(\"train_accList = \",train_accList)\n",
    "print(\"train_lossList = \",train_lossList)\n",
    "print(\"test_accList = \",test_accList)\n",
    "print(\"test_lossList = \",test_lossList)\n",
    "print(\"timeList = \",timeList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 Test set: Average loss: 0.0014, Accuracy: 9754/10000 (98%)\n",
      "lossListPytorch [<built-in method item of Tensor object at 0x7f5f294b9170>, <built-in method item of Tensor object at 0x7f5f294253a0>, <built-in method item of Tensor object at 0x7f5f276bff60>, <built-in method item of Tensor object at 0x7f5f276bf0b0>, <built-in method item of Tensor object at 0x7f5f276bff10>, <built-in method item of Tensor object at 0x7f5f27636cf0>, <built-in method item of Tensor object at 0x7f5f276bf740>, <built-in method item of Tensor object at 0x7f5f812e6b60>, <built-in method item of Tensor object at 0x7f5f276be340>, <built-in method item of Tensor object at 0x7f5f276be7a0>]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义残差块\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, norm=nn.BatchNorm1d, drop_prob=0.1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            norm(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop_prob),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            norm(dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x) + x\n",
    "\n",
    "# 定义MLPResNet模型\n",
    "\n",
    "\n",
    "class MLPResNet(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim=100, num_blocks=3, num_classes=10, norm=nn.BatchNorm1d, drop_prob=0.1):\n",
    "        super(MLPResNet, self).__init__()\n",
    "        # 定义模型结构\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        for _ in range(num_blocks):\n",
    "            self.net.add_module(\n",
    "                'residual_block{}'.format(_),\n",
    "                ResidualBlock(hidden_dim, hidden_dim // 2, norm, drop_prob)\n",
    "            )\n",
    "        self.net.add_module(\n",
    "            'fc',\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "        self.net.add_module(\n",
    "            'log_softmax',\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 定义超参数\n",
    "batch_size = 64\n",
    "learning_rate = 0.1\n",
    "num_epochs = 10\n",
    "\n",
    "# 加载MNIST数据集\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 初始化模型并定义优化器和损失函数\n",
    "model = MLPResNet(dim=784)\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "lossListPytorch = []\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # 将数据加载到CPU\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        output = model(data.view(-1, 784))\n",
    "\n",
    "        # 计算损失\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    lossListPytorch.append(loss.item)\n",
    "\n",
    "# 在测试集上计算模型准确率\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        # 将数据加载到CPU\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        output = model(data.view(-1, 784))\n",
    "\n",
    "        # 计算损失\n",
    "        test_loss += criterion(output, target).item()\n",
    "\n",
    "        # 统计预测正确的样本数量\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "# 打印测试集上的结果\n",
    "test_loss /= len(test_loader.dataset)\n",
    "print('Epoch: {} Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "    epoch, test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "print(\"lossListPytorch\", lossListPytorch)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_nn <class 'mpt.optim.SGD'>\n",
      "Err | Loss\n",
      "12.98% |   0.45212\n",
      "9.01% |   0.31810\n",
      "8.47% |   0.30048\n",
      "8.21% |   0.29172\n",
      "8.07% |   0.28632\n",
      "7.96% |   0.28259\n",
      "7.88% |   0.27984\n",
      "7.81% |   0.27772\n",
      "7.72% |   0.27603\n",
      "7.67% |   0.27465\n",
      "7.85% |   0.27633\n",
      "0.07850 |   0.27633 TEST\n",
      "time:  0:01:12.062722  seconds\n",
      "simple_nn <class 'mpt.optim.Adam'>\n",
      "Err | Loss\n",
      "16.08% |   0.94952\n",
      "19.38% |   0.90033\n",
      "18.37% |   0.97569\n",
      "18.77% |   0.83938\n",
      "20.31% |   1.36762\n",
      "16.59% |   0.76471\n",
      "19.85% |   1.21961\n",
      "17.31% |   1.24014\n",
      "17.76% |   0.78394\n",
      "18.03% |   1.14910\n",
      "16.88% |   0.63192\n",
      "0.16880 |   0.63192 TEST\n",
      "time:  0:01:59.496490  seconds\n",
      "MLPResNet <class 'mpt.optim.SGD'>\n",
      "Err | Loss\n",
      "10.24% |   0.33304\n",
      "4.81% |   0.15718\n",
      "3.42% |   0.11381\n",
      "2.58% |   0.08759\n",
      "1.99% |   0.06944\n",
      "1.56% |   0.05647\n",
      "1.27% |   0.04624\n",
      "1.03% |   0.03872\n",
      "0.87% |   0.03335\n",
      "0.75% |   0.03009\n",
      "2.60% |   0.09090\n",
      "0.02600 |   0.09090 TEST\n",
      "time:  0:11:15.112961  seconds\n",
      "MLPResNet <class 'mpt.optim.Adam'>\n",
      "Err | Loss\n",
      "19.14% |   0.80925\n",
      "21.85% |   0.80273\n",
      "19.65% |   0.76700\n",
      "30.31% |   1.14039\n",
      "24.90% |   0.85596\n",
      "23.91% |   0.85909\n",
      "22.39% |   0.81575\n",
      "27.82% |   0.93165\n",
      "24.14% |   0.76388\n",
      "24.72% |   0.79305\n",
      "21.13% |   0.69540\n",
      "0.21130 |   0.69540 TEST\n",
      "time:  0:11:33.241430  seconds\n"
     ]
    }
   ],
   "source": [
    "train_acc, train_loss = None, None\n",
    "\n",
    "modelSimpleNN = simple_nn()\n",
    "modelResNet = MLPResNet(784, hidden_dim=100)\n",
    "optSGD = mpt.optim.SGD\n",
    "optAdam = mpt.optim.Adam\n",
    "\n",
    "\n",
    "# train 2*2, and visualize\n",
    "modelList = [modelSimpleNN, modelResNet]\n",
    "optList = [optSGD, optAdam]\n",
    "\n",
    "train_accList = []\n",
    "train_lossList = []\n",
    "\n",
    "test_accList = []\n",
    "test_lossList = []\n",
    "timeList = []\n",
    "for (model, opt) in [(model, opt) for model in modelList for opt in optList]:\n",
    "    [train_dataset, train_dataloader, test_dataset, test_dataloader] = loadData()\n",
    "    thisOpt = opt(model[0].parameters(), lr=0.1, weight_decay=0.001)\n",
    "    print(model[1], opt)\n",
    "    print(\"Err | Loss\")\n",
    "    tic()\n",
    "    for _ in range(10):\n",
    "        train_acc, train_loss = epoch(\n",
    "            train_dataloader, model=model[0], opt=thisOpt)\n",
    "    print(\"TEST\")\n",
    "    test_acc, test_loss = epoch(test_dataloader, model=model[0])\n",
    "    t = toc()\n",
    "\n",
    "    timeList.append(t)\n",
    "    train_lossList.append(train_loss)\n",
    "    test_lossList.append(test_loss)\n",
    "    train_accList.append(train_acc)\n",
    "    test_accList.append(test_acc)\n",
    "    print(\"time: \", t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accList:\t [0.07673333333333333, 0.1803, 0.007533333333333334, 0.2472]\n",
      "train_lossList:\t [0.2746484576165676, 1.1491027573744457, 0.030090059110273917, 0.7930528383950393]\n",
      "test_accList:\t [0.0785, 0.1688, 0.026, 0.2113]\n",
      "test_lossList:\t [0.2763303181529045, 0.6319184058904648, 0.09090447120834141, 0.6953959873318672]\n",
      "timeList:\t [datetime.timedelta(seconds=72, microseconds=62722), datetime.timedelta(seconds=119, microseconds=496490), datetime.timedelta(seconds=675, microseconds=112961), datetime.timedelta(seconds=693, microseconds=241430)]\n"
     ]
    }
   ],
   "source": [
    "print(\"train_accList:\\t\",train_accList)\n",
    "print(\"train_lossList:\\t\",train_lossList)\n",
    "print(\"test_accList:\\t\",test_accList)\n",
    "print(\"test_lossList:\\t\",test_lossList)\n",
    "print(\"timeList:\\t\",timeList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'simple_nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[39m# use different learning rate\u001b[39;00m\n",
      "\u001b[1;32m      2\u001b[0m train_acc, train_loss \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;32m----> 4\u001b[0m modelSimpleNN \u001b[39m=\u001b[39m simple_nn()\n",
      "\u001b[1;32m      5\u001b[0m modelResNet \u001b[39m=\u001b[39m MLPResNet(\u001b[39m784\u001b[39m, hidden_dim\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n",
      "\u001b[1;32m      6\u001b[0m optSGD \u001b[39m=\u001b[39m mpt\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'simple_nn' is not defined"
     ]
    }
   ],
   "source": [
    "# use different learning rate\n",
    "train_acc, train_loss = None, None\n",
    "\n",
    "modelSimpleNN = simple_nn()\n",
    "modelResNet = MLPResNet(784, hidden_dim=100)\n",
    "optSGD = mpt.optim.SGD\n",
    "optAdam = mpt.optim.Adam\n",
    "\n",
    "\n",
    "# train 2*2, and visualize\n",
    "modelList = [modelSimpleNN, modelResNet]\n",
    "optList = [optSGD, optAdam]\n",
    "\n",
    "train_accList = []\n",
    "train_lossList = []\n",
    "\n",
    "test_accList = []\n",
    "test_lossList = []\n",
    "timeList = []\n",
    "for (model, opt) in [(model, opt) for model in modelList for opt in optList]:\n",
    "    [train_dataset, train_dataloader, test_dataset, test_dataloader] = loadData()\n",
    "    thisOpt = opt(model[0].parameters(), lr=0.001, weight_decay=0.001)\n",
    "    print(model[1], opt)\n",
    "    print(\"Err | Loss\")\n",
    "    tic()\n",
    "    for _ in range(10):\n",
    "        train_acc, train_loss = epoch(\n",
    "            train_dataloader, model=model[0], opt=thisOpt)\n",
    "    print(\"TEST\")\n",
    "    test_acc, test_loss = epoch(test_dataloader, model=model[0])\n",
    "    t = toc()\n",
    "\n",
    "    timeList.append(t)\n",
    "    train_lossList.append(train_loss)\n",
    "    test_lossList.append(test_loss)\n",
    "    train_accList.append(train_acc)\n",
    "    test_accList.append(test_acc)\n",
    "    print(\"time: \", t, \" seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accList =  [0.15671666666666667, 0.0758, 0.11516666666666667, 0.014366666666666666]\n",
      "train_lossList =  [0.5967742698391278, 0.27257578710714975, 0.3863513117780288, 0.045549460020071514]\n",
      "test_accList =  [0.1456, 0.0763, 0.0895, 0.0297]\n",
      "test_lossList =  [0.5570591828227043, 0.27045953899621966, 0.2983111513406038, 0.09459613444283604]\n",
      "timeList =  [datetime.timedelta(seconds=64, microseconds=939863), datetime.timedelta(seconds=118, microseconds=871126), datetime.timedelta(seconds=711, microseconds=642097), datetime.timedelta(seconds=840, microseconds=721068)]\n"
     ]
    }
   ],
   "source": [
    "print(\"train_accList = \",train_accList)\n",
    "print(\"train_lossList = \",train_lossList)\n",
    "print(\"test_accList = \",test_accList)\n",
    "print(\"test_lossList = \",test_lossList)\n",
    "print(\"timeList = \",timeList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 Test set: Average loss: 0.0014, Accuracy: 9754/10000 (98%)\n",
      "lossListPytorch [<built-in method item of Tensor object at 0x7f5f294b9170>, <built-in method item of Tensor object at 0x7f5f294253a0>, <built-in method item of Tensor object at 0x7f5f276bff60>, <built-in method item of Tensor object at 0x7f5f276bf0b0>, <built-in method item of Tensor object at 0x7f5f276bff10>, <built-in method item of Tensor object at 0x7f5f27636cf0>, <built-in method item of Tensor object at 0x7f5f276bf740>, <built-in method item of Tensor object at 0x7f5f812e6b60>, <built-in method item of Tensor object at 0x7f5f276be340>, <built-in method item of Tensor object at 0x7f5f276be7a0>]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义残差块\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, norm=nn.BatchNorm1d, drop_prob=0.1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            norm(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop_prob),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            norm(dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x) + x\n",
    "\n",
    "# 定义MLPResNet模型\n",
    "\n",
    "\n",
    "class MLPResNet(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim=100, num_blocks=3, num_classes=10, norm=nn.BatchNorm1d, drop_prob=0.1):\n",
    "        super(MLPResNet, self).__init__()\n",
    "        # 定义模型结构\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        for _ in range(num_blocks):\n",
    "            self.net.add_module(\n",
    "                'residual_block{}'.format(_),\n",
    "                ResidualBlock(hidden_dim, hidden_dim // 2, norm, drop_prob)\n",
    "            )\n",
    "        self.net.add_module(\n",
    "            'fc',\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "        self.net.add_module(\n",
    "            'log_softmax',\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 定义超参数\n",
    "batch_size = 64\n",
    "learning_rate = 0.1\n",
    "num_epochs = 10\n",
    "\n",
    "# 加载MNIST数据集\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 初始化模型并定义优化器和损失函数\n",
    "model = MLPResNet(dim=784)\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "lossListPytorch = []\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # 将数据加载到CPU\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        output = model(data.view(-1, 784))\n",
    "\n",
    "        # 计算损失\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    lossListPytorch.append(loss.item)\n",
    "\n",
    "# 在测试集上计算模型准确率\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        # 将数据加载到CPU\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        output = model(data.view(-1, 784))\n",
    "\n",
    "        # 计算损失\n",
    "        test_loss += criterion(output, target).item()\n",
    "\n",
    "        # 统计预测正确的样本数量\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "# 打印测试集上的结果\n",
    "test_loss /= len(test_loader.dataset)\n",
    "print('Epoch: {} Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "    epoch, test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "print(\"lossListPytorch\", lossListPytorch)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4e1d9a8909477db77738c33245c29c7265277ef753467dede8cf3f814cde494e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
